{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e384d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import talib \n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from Tools import *\n",
    "from Tools2 import *\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97e4cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "c = (1,2,3,4,5,6,7,8,9,10,11,12) \n",
    "i=0\n",
    "result=[]\n",
    "while i<len(c):\n",
    "    for j in combinations(c,i):\n",
    "        #print(list(j))\n",
    "        result.append(list(j))\n",
    "    i+=1 \n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba22bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  0.5724137931034483\n",
      "2 :  0.5724137931034483\n",
      "3 :  0.5724137931034483\n",
      "4 :  0.5655172413793104\n",
      "5 :  0.5655172413793104\n",
      "6 :  0.5724137931034483\n",
      "7 :  0.5517241379310345\n",
      "8 :  0.5517241379310345\n",
      "9 :  0.5724137931034483\n",
      "10 :  0.5448275862068965\n",
      "11 :  0.5862068965517241\n",
      "12 :  0.5793103448275863\n",
      "13 :  0.5655172413793104\n"
     ]
    }
   ],
   "source": [
    "start=\"2020-12-31\"\n",
    "end=\"2022-12-31\"\n",
    "name=\"AAPL\"\n",
    "\n",
    "#MACD619RSI21_8020\n",
    "stock_data=pct_change(name,start,end)\n",
    "#stock_data=data.get_data_yahoo(tickers=name,start=start,end=end,progress=False)\n",
    "    \n",
    "stock_data=MACD_short(stock_data)\n",
    "stock_data=RSI(stock_data)\n",
    "stock_data=RSI_MACD(stock_data,21,80,20)\n",
    "\n",
    "#stock_data[\"log_vaolume\"] = np.log(stock_data['Volume'])\n",
    "\n",
    "stock_data = stock_data.dropna()\n",
    "del stock_data[\"real_situation\"]\n",
    "del stock_data[\"Position\"]\n",
    "del stock_data[\"Close_price_percentage\"]\n",
    "#print(stock_data)\n",
    "\n",
    "y = np.where(stock_data['Close'].shift(-1) > stock_data['Close'],1,-1)\n",
    "\n",
    "for i in range(1,14):\n",
    "    #standardScaler\n",
    "    X = stock_data.iloc[:,:i]\n",
    "    st_x= StandardScaler()  \n",
    "    X= st_x.fit_transform(X)  \n",
    "    \n",
    "    #PCA\n",
    "    #pca = PCA(n_components=2)\n",
    "    #X = pca.fit_transform(X)\n",
    "    \n",
    "    #split dataset\n",
    "    split = int(0.7*len(stock_data))\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "    \n",
    "    #logistic regression\n",
    "    model = LogisticRegression(max_iter=20000)\n",
    "    model = model.fit (X_train,y_train)\n",
    "    probability = model.predict_proba(X_test)\n",
    "    predicted = model.predict(X_test)\n",
    "    #result\n",
    "    #print(metrics.classification_report(y_test, predicted))\n",
    "    #print(metrics.confusion_matrix(y_test, predicted)) \n",
    "    print(i,\": \",model.score(X_test,y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5980113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  0.5655172413793104\n",
      "2 :  0.5655172413793104\n",
      "3 :  0.5586206896551724\n",
      "4 :  0.5655172413793104\n",
      "5 :  0.5724137931034483\n",
      "6 :  0.5724137931034483\n",
      "7 :  0.5586206896551724\n",
      "8 :  0.5517241379310345\n",
      "9 :  0.5586206896551724\n",
      "10 :  0.5517241379310345\n",
      "11 :  0.5517241379310345\n",
      "12 :  0.5586206896551724\n",
      "13 :  0.5310344827586206\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(1,14):\n",
    "    #normalization MinMaxScalar\n",
    "    X = stock_data.iloc[:,:i]\n",
    "    st_x= MinMaxScaler()   \n",
    "    X= st_x.fit_transform(X)  \n",
    "    \n",
    "    #PCA\n",
    "   # pca = PCA(n_components=2)\n",
    "   # X = pca.fit_transform(X)\n",
    "    \n",
    "    #split dataset\n",
    "    split = int(0.7*len(stock_data))\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "    \n",
    "    #logistic regression\n",
    "    model = LogisticRegression(max_iter=20000)\n",
    "    model = model.fit (X_train,y_train)\n",
    "    probability = model.predict_proba(X_test)\n",
    "    predicted = model.predict(X_test)\n",
    "    #result\n",
    "    #print(metrics.classification_report(y_test, predicted))\n",
    "    #print(metrics.confusion_matrix(y_test, predicted)) \n",
    "    print(i,\": \",model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2fd0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 :  0.5517241379310345\n"
     ]
    }
   ],
   "source": [
    "#standardScaler\n",
    "X = stock_data.iloc[:,:13]\n",
    "st_x= StandardScaler()  \n",
    "X= st_x.fit_transform(X)  \n",
    "    \n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "    \n",
    "#split dataset\n",
    "split = int(0.7*len(stock_data))\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "    \n",
    "#logistic regression\n",
    "model = LogisticRegression(max_iter=20000)\n",
    "model = model.fit (X_train,y_train)\n",
    "probability = model.predict_proba(X_test)\n",
    "predicted = model.predict(X_test)\n",
    "#result\n",
    "#print(metrics.classification_report(y_test, predicted))\n",
    "#print(metrics.confusion_matrix(y_test, predicted)) \n",
    "print(i,\": \",model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af81de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 :  0.5448275862068965\n"
     ]
    }
   ],
   "source": [
    "#normalization MinMaxScalar\n",
    "X = stock_data.iloc[:,:13]\n",
    "st_x= MinMaxScaler()   \n",
    "X= st_x.fit_transform(X)  \n",
    "    \n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "    \n",
    "#split dataset\n",
    "split = int(0.7*len(stock_data))\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "#logistic regression\n",
    "model = LogisticRegression(max_iter=20000)\n",
    "model = model.fit (X_train,y_train)\n",
    "probability = model.predict_proba(X_test)\n",
    "predicted = model.predict(X_test)\n",
    "#result\n",
    "#print(metrics.classification_report(y_test, predicted))\n",
    "#print(metrics.confusion_matrix(y_test, predicted)) \n",
    "print(i,\": \",model.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
